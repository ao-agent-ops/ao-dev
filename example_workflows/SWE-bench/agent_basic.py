#!/usr/bin/env python3

"""
Generate a single SWE-bench prediction by making one call to Claude Sonnet.

Writes JSONL with entries of the form:
  {"instance_id": ..., "model_name_or_path": ..., "model_patch": ...}

Example:
  python example_workflows/SWE-bench/agent.py \
    --dataset_name princeton-nlp/SWE-bench_Lite \
    --split test \
    --output predictions.jsonl \
    --instance_id sympy__sympy-20590

Then evaluate:
  python -m swebench.harness.run_evaluation \
    --dataset_name princeton-nlp/SWE-bench_Lite \
    --predictions_path predictions.jsonl \
    --max_workers 4 \
    --run_id claude_one_call
"""

import argparse
import json
import os
import re
from pathlib import Path

from datasets import load_dataset

try:
    import anthropic
except Exception as e:
    raise RuntimeError(
        "anthropic package is required. Please ensure it is installed and ANTHROPIC_API_KEY is set."
    ) from e


def _strip_code_fences(text: str) -> str:
    """Remove surrounding triple backtick fences if present."""
    text = text.strip()
    fence_match = re.match(r"^```[a-zA-Z0-9_-]*\n([\s\S]*?)\n```$", text)
    if fence_match:
        return fence_match.group(1).strip()
    # Also handle cases with leading/trailing fences only
    text = re.sub(r"^```[a-zA-Z0-9_-]*\n", "", text)
    text = re.sub(r"\n```$", "", text)
    return text.strip()


def build_prompt(instance: dict) -> str:
    """Construct a one-shot prompt for generating a unified diff patch."""
    problem = instance.get("problem_statement", "")
    repo = instance.get("repo", "")
    base_commit = instance.get("base_commit", "")
    instance_id = instance.get("instance_id", "")

    return (
        "You are an expert software engineer participating in the SWE-bench benchmark.\n"
        "Given the following task, produce ONLY a valid unified diff patch that applies cleanly\n"
        "to the repository. Do not include explanations or surrounding code fences.\n\n"
        f"Repository: {repo}\n"
        f"Base commit: {base_commit}\n"
        f"Instance ID: {instance_id}\n\n"
        "Task (problem_statement):\n"
        f"{problem}\n\n"
        "Requirements:\n"
        "- Output must be a unified diff generated by `git diff` or equivalent.\n"
        "- Use paths prefixed with a/ and b/ (e.g., --- a/file.py, +++ b/file.py).\n"
        "- Include correct @@ hunk headers and context lines.\n"
        "- Do not add any commentary or markdown fences; output the patch only.\n"
    )


def main():
    parser = argparse.ArgumentParser(description="One-call Claude Sonnet SWE-bench predictor")
    parser.add_argument(
        "--dataset_name",
        type=str,
        default="princeton-nlp/SWE-bench_Lite",
        help="Hugging Face dataset name (e.g., princeton-nlp/SWE-bench_Lite)",
    )
    parser.add_argument(
        "--split",
        type=str,
        default="test",
        help="Dataset split (e.g., dev or test)",
    )
    parser.add_argument(
        "--instance_id",
        type=str,
        default=None,
        help="Specific instance_id to predict (defaults to first instance in split)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="predictions.jsonl",
        help="Path to write predictions JSONL",
    )
    parser.add_argument(
        "--model",
        type=str,
        default=os.getenv("ANTHROPIC_MODEL", "claude-3-7-sonnet-20250219"),
        help=(
            "Anthropic model name. Defaults to Claude Sonnet (latest known id). "
            "Override via --model or ANTHROPIC_MODEL."
        ),
    )
    parser.add_argument(
        "--max_tokens",
        type=int,
        default=2000,
        help="Max tokens for Claude response",
    )
    args = parser.parse_args()

    ds = load_dataset(args.dataset_name, split=args.split)
    if args.instance_id:
        matches = [row for row in ds if row.get("instance_id") == args.instance_id]
        if not matches:
            raise SystemExit(f"instance_id not found in dataset: {args.instance_id}")
        instance = matches[0]
    else:
        instance = ds[0]

    prompt = build_prompt(instance)

    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        raise SystemExit("Please set ANTHROPIC_API_KEY in your environment.")

    client = anthropic.Anthropic(api_key=api_key)
    msg = client.messages.create(
        model=args.model,
        max_tokens=args.max_tokens,
        messages=[
            {
                "role": "user",
                "content": prompt,
            }
        ],
    )

    # Extract text content
    parts = []
    for part in msg.content:
        # part can be TextBlock or other types; we only need text
        text = getattr(part, "text", None)
        if text:
            parts.append(text)
    patch = _strip_code_fences("\n".join(parts).strip())

    # Prepare prediction entry
    pred = {
        "instance_id": instance["instance_id"],
        "model_name_or_path": args.model,
        "model_patch": patch,
    }

    out_path = Path(args.output)
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open("w", encoding="utf-8") as f:
        f.write(json.dumps(pred) + "\n")

    print(f"Wrote 1 prediction to: {out_path.resolve()}")
    print(
        "Run evaluation:\n"
        "  python -m swebench.harness.run_evaluation \\\n+\n"
        "    --dataset_name princeton-nlp/SWE-bench_Lite \\\n+\n"
        f"    --predictions_path {out_path.resolve()} \\\n+\n"
        "    --max_workers 4 \\\n+\n"
        "    --run_id claude_one_call\n"
    )


if __name__ == "__main__":
    main()


